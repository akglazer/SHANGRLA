{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ballot Polling Assertion RLA Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import math\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from assertion_audit_utils import \\\n",
    "    Assertion, Assorter, CVR, TestNonnegMean, check_audit_parameters,\\\n",
    "    find_p_values, summarize_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: All votes only rank the reported winner 1st\n",
    "\n",
    "The reported winner of this contest is Candidate 15 with the elimination order of the remaining candidates listed as \\[45, 16, 17, 18\\]. 200 votes are sampled from the manifest and luckily represent the population exactly which involve 10 times the votes of the sample. The MVRs all have candidate 15 ranked first and other candidates left blank. \n",
    "\n",
    "IRV Elimination process (4-way tie):\n",
    "\n",
    "- WO - 15 v 45 : Candidate 15 has more 1st rank votes (2000) than Candidate 45 appearances (0) in the remaining ballots\n",
    "\n",
    "- WO - 15 v 16 : Candidate 15 has more 1st rank votes (2000) than Candidate 16 appearances (0) in the remaining ballots\n",
    "\n",
    "- WO - 15 v 17 : Candidate 15 has more 1st rank votes (2000) than Candidate 17 appearances (0) in the remaining ballots\n",
    "\n",
    "- WO - 15 v 18 : Candidate 15 has more 1st rank votes (2000) than Candidate 18 appearances (0) in the remaining ballots\n",
    "\n",
    "Since candidate 15 has garnered the majority of sampled votes, candidate 15 wins. Candidates 16, 17, 18, and 45 (write-in) lose in a tie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contests to audit.\n",
    "contests = {'339':{'risk_limit': 0.05,\n",
    "                     'choice_function':'IRV',\n",
    "                     'n_winners':1,\n",
    "                     'candidates':['15','16','17','18'],\n",
    "                     'reported_winners' : ['15'],\n",
    "                     'assertion_file' : './Data/assertion_polling_example_1.json'\n",
    "                    }\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvr_file = './Data/mvr_polling_example_1.json'\n",
    "manifest_type = 'STYLE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define risk function\n",
    "risk_function = \"kaplan_wald\"\n",
    "risk_fn = lambda x: TestNonnegMean.kaplan_wald(np.array(x), t=1/2, g=g, random_order=True)\n",
    "\n",
    "g = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the assertions for the IRV contest\n",
    "for c in contests:\n",
    "    if contests[c]['choice_function'] == 'IRV':\n",
    "        with open(contests[c]['assertion_file'], 'r') as f:\n",
    "            contests[c]['assertion_json'] = json.load(f)['audits'][0]['assertions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the dict of dicts of assertions for each contest\n",
    "all_assertions = Assertion.make_all_assertions(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_audit_parameters(risk_function, g, contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the audited sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(mvr_file) as f:\n",
    "    mvr_json = json.load(f)\n",
    "\n",
    "mvr_sample = CVR.from_dict(mvr_json['ballots'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find measured risks for all assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum assertion p-value 1.7753329329317256e-56\n",
      "p-values for assertions in contest 339\n",
      "15 v 16 1.7753329329317256e-56\n",
      "15 v 17 1.7753329329317256e-56\n",
      "15 v 18 1.7753329329317256e-56\n",
      "15 v 45 1.7753329329317256e-56\n",
      "\n",
      "contest 339 AUDIT COMPLETE at risk limit 0.05. Attained risk 1.7753329329317256e-56\n"
     ]
    }
   ],
   "source": [
    "p_max = find_p_values(contests, all_assertions, risk_fn, manifest_type, mvr_sample)\n",
    "print(\"maximum assertion p-value {}\".format(p_max))\n",
    "done = summarize_status(contests, all_assertions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_p = ((1-g)*2+g)**(-1)\n",
    "loser_p = g**(-1)\n",
    "np.testing.assert_almost_equal(contests['339']['p_values']['15 v 16'], min(1, winner_p**200*loser_p**0))\n",
    "np.testing.assert_almost_equal(contests['339']['p_values']['15 v 17'], min(1, winner_p**200*loser_p**0))\n",
    "np.testing.assert_almost_equal(contests['339']['p_values']['15 v 18'], min(1, winner_p**200*loser_p**0))\n",
    "np.testing.assert_almost_equal(contests['339']['p_values']['15 v 45'], min(1, winner_p**200*loser_p**0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Votes distributed among candidates\n",
    "\n",
    "The reported winner of this contest is Candidate 15 with the elimination order of the remaining candidates reported as \\[45, 18, 17, 16\\]. 200 votes are sampled from the manifest. The MVRs show 4 different rankings amongst the sampled ballots. 10 votes mark \\[18, 17, 16, 15\\], 20 votes mark \\[17, 16, 15\\], 30 votes mark \\[16, 15\\], and 140 votes mark \\[15\\]. \n",
    "\n",
    "IRV Elimination process:\n",
    "\n",
    "1. WO - 15 v 45 : Candidate 15 has more 1st rank votes (200) than Candidate 45 appearances (0) in the remaining ballots. \n",
    "\n",
    "    Rank | 10 ballots | 20 ballots | 30 ballots | 140 ballots\n",
    "    ---|---|---|---|---\n",
    "    1 | 18 | 17 | 16 | 15 \n",
    "    2 | 17 | 16 | 15 |-\n",
    "    3 | 16 | 15 | - | -\n",
    "    4 | 15 | - | - | - \n",
    "\n",
    "    No ballots need to be redistributed. \n",
    "\n",
    "2. WO - 15 v 18 : Candidate 15 has more 1st rank votes (140) than Candidate 18 appearances (10) in the remaining ballots. \n",
    "\n",
    "    Rank | 10 ballots | 20 ballots | 30 ballots | 140 ballots\n",
    "    ---|---|---|---|---\n",
    "    1 | - | 17 | 16 | 15 \n",
    "    2 | 17 | 16 | 15 |-\n",
    "    3 | 16 | 15 | - | -\n",
    "    4 | 15 | - | - | - \n",
    "    \n",
    "    The 10 ballots ranking 18 first are redistributed to 17. \n",
    "\n",
    "3. WO - 15 v 17 : Candidate 15 has more 1st rank votes (140) than Candidate 17 appearances (30) in the remaining ballots.\n",
    "\n",
    "    Rank | 10 ballots | 20 ballots | 30 ballots | 140 ballots\n",
    "    ---|---|---|---|---\n",
    "    1 | - | - | 16 | 15 \n",
    "    2 | - | 16 | 15 |-\n",
    "    3 | 16 | 15 | - | -\n",
    "    4 | 15 | - | - | - \n",
    "    \n",
    "    The 10 ballots ranking 17 second and the 20 ballots ranking 17 first are redistributed to 16.\n",
    "\n",
    "4. WO - 15 v 16 : Candidate 15 has more 1st rank votes (140) than Candidate 16 appearances (60) in the remaining ballots. Thus, Candidate 15 is the winner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contests to audit.\n",
    "contests = {'339':{'risk_limit': 0.05,\n",
    "                     'choice_function':'IRV',\n",
    "                     'n_winners':1,\n",
    "                     'candidates':['15','16','17','18'],\n",
    "                     'reported_winners' : ['15'],\n",
    "                     'assertion_file' : './Data/assertion_polling_example_2.json'\n",
    "                    }\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvr_file = './Data/mvr_polling_example_2.json'\n",
    "manifest_type = 'STYLE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define risk function\n",
    "risk_function = \"kaplan_wald\"\n",
    "risk_fn = lambda x: TestNonnegMean.kaplan_wald(np.array(x), t=1/2, g=g, random_order=False)\n",
    "\n",
    "g = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the assertions for the IRV contest\n",
    "for c in contests:\n",
    "    if contests[c]['choice_function'] == 'IRV':\n",
    "        with open(contests[c]['assertion_file'], 'r') as f:\n",
    "            contests[c]['assertion_json'] = json.load(f)['audits'][0]['assertions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the dict of dicts of assertions for each contest\n",
    "all_assertions = Assertion.make_all_assertions(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_audit_parameters(risk_function, g, contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the audited sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mvr_file) as f:\n",
    "    mvr_json = json.load(f)\n",
    "\n",
    "mvr_sample = CVR.from_dict(mvr_json['ballots'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find measured risk for all assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum assertion p-value 1.0\n",
      "p-values for assertions in contest 339\n",
      "15 v 16 1.0\n",
      "15 v 17 9.429656367453732e-10\n",
      "15 v 18 9.429656367453743e-30\n",
      "15 v 45 9.42965636745375e-40\n",
      "\n",
      "contest 339 audit INCOMPLETE at risk limit 0.05. Attained risk 1.0\n",
      "assertions remaining to be proved:\n",
      "15 v 16: current risk 1.0\n"
     ]
    }
   ],
   "source": [
    "p_max = find_p_values(contests, all_assertions, risk_fn, manifest_type, mvr_sample)\n",
    "print(\"maximum assertion p-value {}\".format(p_max))\n",
    "done = summarize_status(contests, all_assertions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "winner_p = ((1-g)*2+g)**(-1)\n",
    "loser_p = g**(-1)\n",
    "np.testing.assert_almost_equal(contests['339']['p_values']['15 v 16'], min(1, winner_p**140*loser_p**60))\n",
    "np.testing.assert_almost_equal(contests['339']['p_values']['15 v 17'], min(1, winner_p**140*loser_p**30))\n",
    "np.testing.assert_almost_equal(contests['339']['p_values']['15 v 18'], min(1, winner_p**140*loser_p**10))\n",
    "np.testing.assert_almost_equal(contests['339']['p_values']['15 v 45'], min(1, winner_p**140*loser_p**0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
